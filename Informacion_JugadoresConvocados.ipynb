{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce21540",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importamos las librerías necesarias\n",
    "import requests ## permite realizar solicitudes HTTP\n",
    "from bs4 import BeautifulSoup ## crea la \"sopa\", es decir, extrae el código de HTML de la página para poder obtener los datos \n",
    "import re ## busca patrones de texto\n",
    "import pandas as pd ##crea y manipula Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9daea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### El siguiente código accede a la página de Transfermarkt que tiene el ranking FIFA del 9 de enero del 2023.\n",
    "### Después, descarga los enlaces para el perfil de cada equipo y los modifica para poderlos utilizar en el siguiente código.\n",
    "## Para finalizar, guarda los enlaces modificados, el nombre de la selección y el año de análisis en un mismo diccionario.\n",
    "\n",
    "page= 'https://www.transfermarkt.mx/statistik/weltrangliste/statistik/stat/plus/0/galerie/0?datum=2023-01-09' ## Colocamos la página de las selecciones\n",
    "headers = {'User-Agent' : 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari537.36'} ## esta línea agrega algunos \"headers\" que ayudan a evitar que las páginas bloqueen la petición \n",
    "page_tree = requests.get(page, headers=headers) ## pedimos la información de la página\n",
    "soup = BeautifulSoup(page_tree.content, 'html.parser') ## creamos la \"sopa\"\n",
    "table= soup.find('table', {'class':'items'}) ## encontramos la tabla de donde queremos obtener la información (esto ya es del código de html)\n",
    "table_body= table.find('tbody') ## seleccionamos sólo el cuerpo de la tabla\n",
    "tds= table_body.find_all('td', {'class':'hauptlink'}) ## seleccionamos los datos específicos que necesitamos (depende del html)\n",
    "seleccionlink={'Selección':[],'Link':[], 'Year':[]} ## creamos un diccionario para guardar los datos\n",
    "linksolo=[] ## creamos un vector en donde guardaremos los enlaces como están en la página para después manipularlos\n",
    "tdsnecesarios=[]## creamos un vector que guarde solo los valores de las filas que necesitamos\n",
    "seleccion=[]## vector que guarda los nombres de las selecciones\n",
    "for y in range(0, len(tds), 2): \n",
    "    tdsnecesarios.append(y) ## guarda los números de las filas específicas que necesitamos\n",
    "for j, te in enumerate(tds):\n",
    "    for sele in range(0, len(tdsnecesarios)):\n",
    "        if j==tdsnecesarios[sele]: ## comparamos el número de la fila con el vector que habíamos creado\n",
    "            img=te.find('img') ## encontramos el nombre\n",
    "            a=te.find('a') ## encontramos el enlace\n",
    "            seleccion.append(img['alt']) ## guardamos el nombre\n",
    "            linksolo.append(a['href']) ## guardamos el enlace\n",
    "for l in range(0,len(seleccion)):\n",
    "    for year in range(2009, 2022):\n",
    "            y = str(year) ## guardamos el año\n",
    "            seleccionlink['Selección'].append(seleccion[l]) ## guardamos el nombre del equipo en el diccionario\n",
    "            seleccionlink['Link'].append('https://www.transfermarkt.mx' + linksolo[l] + '?saison_id=' + y) ## modificamos el enlace y lo guardamos en el diccionario\n",
    "            seleccionlink['Year'].append(y) ## guardamos el año en el diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7047a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## El siguiente código accede al perfil de cada equipo nacional en los años que analizo. Después, obtiene el nombre, posición,\n",
    "## enlace al perfil, lugar de nacimiento (país), fecha de debut en el equipo, edad y su nombre completo. Posteriormente,\n",
    "## modifica el enlace de tal manera que muestre su rendimiento (este es el enlace que muestra las ligas en las que ha jugado a \n",
    "## lo largo de su carrera) y obtiene la liga en la que jugó, la temporada y los minutos.\n",
    "\n",
    "jugadorcompleto={'Name':[],'UniqueName':[],'BirthPlace':[],'FinalNationalTeam':[], 'Debut':[],'NationalTeam':[],'Year':[],\n",
    "                 'Season':[],'League':[],'Age':[],'Minutes':[],'Position':[]} ## creamos el diccionario para los datos (finales) que necesitamos\n",
    "for i in range(0,n):## este número se modifica de acuerdo al equipo y año de la que queremos que obtenga los datos\n",
    "    selección = seleccionlink['Selección'][i]## definimos el nombre del equipo de acuerdo con el índice del diccionario del código anterior \n",
    "    año = int(seleccionlink['Year'][i])+1 ## definimos el año de acuerdo con el índice del diccionario del código anterior +1 \n",
    "    page = seleccionlink['Link'][i] ## definimos el enlace de acuerdo con el índice del diccionario del código anterior\n",
    "    headers = {'User-Agent' : 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari537.36'} ## esta línea y las que siguen son idénticas a las líneas del código anterior\n",
    "    page_tree = requests.get(page, headers=headers)\n",
    "    soup = BeautifulSoup(page_tree.content, 'html.parser')\n",
    "    table= soup.find('table', {'class':'items'})\n",
    "    table_body= table.find('tbody')\n",
    "    tds= table_body.find_all('td', {'class':'zentriert'})\n",
    "    ## NOTA: La mayoría del código siguiente depende de la página, tome en cuenta que este código está diseñado específicamente\n",
    "    ## para Transfermarkt, si necesita una mayor explicación contacte directamente al autor\n",
    "    inline_tables=table_body.find_all('table', {'class':'inline-table'})\n",
    "    clubs=[]\n",
    "    ages=[]\n",
    "    for i in range(1, len(tds),3):\n",
    "        ages.append(i)\n",
    "    nameypos={'Name':[],'Position':[],'Links':[],'Linksrend':[],'LugardeNac':[],'Debut':[],\n",
    "              'Selec':[],'Age':[],'NombreID':[]} ## creamos un diccionario intermedio para guardar los datos que podemos obtener a partir de los primeros enlaces y que guarda los enlaces modificados\n",
    "    for x in inline_tables:\n",
    "        player = x.find('img')\n",
    "        nameypos['Name'].append(player['alt'])\n",
    "    for jk in inline_tables:\n",
    "        tds2=jk.find_all('td')\n",
    "        nameypos['Position'].append(tds2[2].text)\n",
    "    getlink=[]\n",
    "    for row in inline_tables:\n",
    "        player_link = row.find('td', {'class':'hauptlink'})\n",
    "        getlink.append(player_link)\n",
    "    profile=[]\n",
    "    for l in getlink:\n",
    "        href=l.find('a')\n",
    "        profile.append(href['href'])\n",
    "    for h in profile:\n",
    "        if h is not None:\n",
    "            nameypos['Links'].append('https://www.transfermarkt.mx'+ h)\n",
    "        else:\n",
    "            nameypos['Links'].append('No Link')\n",
    "    for link in nameypos['Links']:\n",
    "        perfil=link\n",
    "        rend= perfil.replace('profil', 'detaillierteleistungsdaten')\n",
    "        nameypos['Linksrend'].append(rend)\n",
    "    needed=[0,2]\n",
    "    for i in range(0, len(nameypos['Name'])):\n",
    "        page = nameypos['Links'][i]\n",
    "        headers = {'User-Agent' : 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari537.36'}\n",
    "        page_tree = requests.get(page, headers=headers)\n",
    "        soup = BeautifulSoup(page_tree.content, 'html.parser')\n",
    "        info=soup.find('div', {'class':'data-header__details'})\n",
    "        items=info.find_all('ul')\n",
    "        fichatec=soup.find('div',{'class':'info-table info-table--right-space'})\n",
    "        if fichatec is not None:\n",
    "            span=fichatec.find_all('span',{'class':'info-table__content info-table__content--bold'})\n",
    "            nombrecomp=span[0].text\n",
    "            nameypos['NombreID'].append(nombrecomp)\n",
    "        else:\n",
    "            nameypos['NombreID'].append('NA')\n",
    "        lis=[]\n",
    "        for g in items:\n",
    "            dataheaders=g.find_all(\"li\")\n",
    "            lis.append(dataheaders)\n",
    "        necesario=[]\n",
    "        for f,s in enumerate(lis):\n",
    "            for t in range(0, len(needed)):\n",
    "                if f == needed[t]:\n",
    "                    necesario.append(s)\n",
    "        if len(necesario[0])>=2:\n",
    "            nac=necesario[0][1].find('img')\n",
    "            if nac is not None:\n",
    "                nameypos['LugardeNac'].append(nac['alt'])\n",
    "            else: \n",
    "                nameypos['LugardeNac'].append('Revisar')\n",
    "        else:\n",
    "            nameypos['LugardeNac'].append('Revisar')\n",
    "        if len(necesario[1])!=0:\n",
    "            sel=necesario[1][0].find('img')\n",
    "            nameypos['Selec'].append(sel['alt'])\n",
    "            carsels=soup.find('div',{'data-viewport':'Laenderspielkarriere'})\n",
    "            fecha=carsels.find_all('div',{'class':'grid__cell grid__cell--center'})\n",
    "            ade=fecha[0].find('a')\n",
    "            if ade is not None:\n",
    "                debut=ade.text\n",
    "                nameypos['Debut'].append(debut)\n",
    "            else:\n",
    "                debut=fecha[0].text\n",
    "                debutcl=debut.replace(\"\\n\", \"\").replace(\"\\t\", \"\").replace(\" \", \"\")\n",
    "                nameypos['Debut'].append(debutcl)\n",
    "        else:\n",
    "            nameypos['Selec'].append('NA')\n",
    "            nameypos['Debut'].append('NA')\n",
    "        for j, row in enumerate(tds):\n",
    "            if j in ages:\n",
    "                    age=row.text\n",
    "                    if age is not None:\n",
    "                        nameypos['Age'].append(age)\n",
    "                    else:\n",
    "                        nameypos['Age'].append('0')\n",
    "    for i in range(0, len(nameypos['Name'])):\n",
    "        posicion=nameypos['Position'][i]\n",
    "        nombreid=nameypos['NombreID'][i]\n",
    "        edad=nameypos['Age'][i]\n",
    "        seleccionquerepresenta=nameypos['Selec'][i]\n",
    "        debutsele=nameypos['Debut'][i]\n",
    "        nacimiento=nameypos['LugardeNac'][i]\n",
    "        nombre=nameypos['Name'][i]\n",
    "        page_rend = nameypos['Linksrend'][i]\n",
    "        pagerend_tree = requests.get(page_rend, headers=headers)\n",
    "        soup_rend = BeautifulSoup(pagerend_tree.content, 'html.parser')\n",
    "        table = soup_rend.find('div', {'class': 'responsive-table'})\n",
    "        body = table.find('tbody')\n",
    "        if body is not None:\n",
    "            temp = body.find_all('td', {'class': 'zentriert'})\n",
    "            comp = body.find_all('td', {'class': 'hauptlink no-border-links'})\n",
    "            mins = body.find_all('td', {'class': 'rechts'})\n",
    "            tempn = []\n",
    "            if nameypos['Position'][i] == 'Portero':\n",
    "                for y in range(0, len(temp), 6):\n",
    "                    tempn.append(y)\n",
    "            else:\n",
    "                for y in range(0, len(temp), 8):\n",
    "                    tempn.append(y)\n",
    "            for j, te in enumerate(temp):\n",
    "                for h in range(0, len(tempn)):\n",
    "                    if j == tempn[h]:\n",
    "                        im = te.text\n",
    "                        jugadorcompleto['Position'].append(posicion)\n",
    "                        jugadorcompleto['Age'].append(edad)\n",
    "                        jugadorcompleto['FinalNationalTeam'].append(seleccionquerepresenta)\n",
    "                        jugadorcompleto['Debut'].append(debutsele)\n",
    "                        jugadorcompleto['BirthPlace'].append(nacimiento)\n",
    "                        jugadorcompleto['UniqueName'].append(nombreid)\n",
    "                        jugadorcompleto['Name'].append(nombre)\n",
    "                        jugadorcompleto['NationalTeam'].append(selección)\n",
    "                        jugadorcompleto['Year'].append(año)\n",
    "                        jugadorcompleto['Season'].append(im)\n",
    "            for z in comp:\n",
    "                lig=z.find('a')\n",
    "                jugadorcompleto['League'].append(lig.text)\n",
    "            for w in mins:\n",
    "                text = w.text\n",
    "                mj = ''.join(caracter for caracter in text if caracter.isdigit() or caracter == '.')\n",
    "                mj_f = mj.replace('.', '')\n",
    "                if mj_f == '':\n",
    "                    jugadorcompleto['Minutes'].append(int('1'))\n",
    "                else:\n",
    "                    jugadorcompleto['Minutes'].append(int(mj_f))\n",
    "        else:\n",
    "            jugadorcompleto['Position'].append(posicion)\n",
    "            jugadorcompleto['Age'].append(edad)\n",
    "            jugadorcompleto['FinalNationalTeam'].append(seleccionquerepresenta)\n",
    "            jugadorcompleto['Debut'].append(debutsele)\n",
    "            jugadorcompleto['BirthPlace'].append(nacimiento)\n",
    "            jugadorcompleto['UniqueName'].append(nombreid)\n",
    "            jugadorcompleto['NationalTeam'].append(selección)\n",
    "            jugadorcompleto['Year'].append(año)\n",
    "            jugadorcompleto['Name'].append(nombre)\n",
    "            jugadorcompleto['Season'].append('NA')\n",
    "            jugadorcompleto['League'].append('NA')\n",
    "            jugadorcompleto['Minutes'].append('NA')\n",
    "## NOTA: algunos jugadores y equipos tienen páginas construidas de diferente forma. Para estos, rellenamos el diccionario con 'NA'\n",
    "## lo que nos permite crear el Data Frame sin errores. Estos datos fueron corroborados manualmente y corregidos en caso de que fuera\n",
    "## necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313759be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "players=pd.DataFrame(jugadorcompleto) ## creamos un data frame a partir del diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9477945",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convertimos el data frame en excel y lo guardamos\n",
    "players.to_excel('C:/Nombre.xlsx', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102925ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
